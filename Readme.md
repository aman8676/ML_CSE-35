# ğŸ“Š Data Collection Project (Manual Data â€¢ API Fetch â€¢ Web Scraping)

This project demonstrates **three different methods** of collecting and storing data using Python:

1. **Manual Data Creation (CSV Generation)**
2. **API Data Fetching (Fake Store API)**
3. **Web Scraping (Books to Scrape Website)**

Each method generates a CSV file which can be used for analysis, ML models, dashboards, or further processing.

---

---

## ğŸ“ 1. Manual Data Creation

In this method, data is manually created using Python dictionaries and converted into a Pandas DataFrame.  
The dataset is then saved as a CSV file.

### âœ” Output File

`manual_data.csv`

### âœ” Purpose

- Understand DataFrames
- Practice saving data
- Learn basic data processing

---

---

## ğŸŒ 2. API Data Fetching (Fake Store API)

This script fetches product data from the **Fake Store API**, a free public API for testing.

### âœ” Code Summary

- Loop through product API endpoints
- Extract: **title, price, category, rating**
- Store all products in a DataFrame
- Save to `product_data.csv`

### âœ” Output File

`product_data.csv`

### âœ” Concepts Covered

- HTTP GET requests
- JSON data handling
- Converting API data into CSV

---

---

## ğŸ•¸ï¸ 3. Web Scraping (Books to Scrape)

This script scrapes book information from the website:  
ğŸ‘‰ https://books.toscrape.com/

### âœ” Data Extracted

- **Book Title**
- **Price**
- **Availability Status**

### âœ” Tools Used

- `requests` â€” Fetch webpage HTML
- `BeautifulSoup` â€” Parse and extract content
- `pandas` â€” Build and save dataset

### âœ” Output File

`books_data.csv`

### âœ” scrape_books.py Overview

The script includes:

- `fetch_page()` â†’ Downloads webpage HTML
- `parse_books()` â†’ Extracts book data from HTML
- Saves results into a CSV file
- Displays a preview of the first 10 rows

---

---

# ğŸ“‚ Final Project Structure
